
/* !!! This is code generated by Prisma. Do not edit directly. !!!
/* eslint-disable */

Object.defineProperty(exports, "__esModule", { value: true });

const {
  PrismaClientKnownRequestError,
  PrismaClientUnknownRequestError,
  PrismaClientRustPanicError,
  PrismaClientInitializationError,
  PrismaClientValidationError,
  getPrismaClient,
  sqltag,
  empty,
  join,
  raw,
  skip,
  Decimal,
  Debug,
  objectEnumValues,
  makeStrictEnum,
  Extensions,
  warnOnce,
  defineDmmfProperty,
  Public,
  getRuntime,
  createParam,
} = require('./runtime/wasm-engine-edge.js')


const Prisma = {}

exports.Prisma = Prisma
exports.$Enums = {}

/**
 * Prisma Client JS version: 6.17.1
 * Query Engine version: 272a37d34178c2894197e17273bf937f25acdeac
 */
Prisma.prismaVersion = {
  client: "6.17.1",
  engine: "272a37d34178c2894197e17273bf937f25acdeac"
}

Prisma.PrismaClientKnownRequestError = PrismaClientKnownRequestError;
Prisma.PrismaClientUnknownRequestError = PrismaClientUnknownRequestError
Prisma.PrismaClientRustPanicError = PrismaClientRustPanicError
Prisma.PrismaClientInitializationError = PrismaClientInitializationError
Prisma.PrismaClientValidationError = PrismaClientValidationError
Prisma.Decimal = Decimal

/**
 * Re-export of sql-template-tag
 */
Prisma.sql = sqltag
Prisma.empty = empty
Prisma.join = join
Prisma.raw = raw
Prisma.validator = Public.validator

/**
* Extensions
*/
Prisma.getExtensionContext = Extensions.getExtensionContext
Prisma.defineExtension = Extensions.defineExtension

/**
 * Shorthand utilities for JSON filtering
 */
Prisma.DbNull = objectEnumValues.instances.DbNull
Prisma.JsonNull = objectEnumValues.instances.JsonNull
Prisma.AnyNull = objectEnumValues.instances.AnyNull

Prisma.NullTypes = {
  DbNull: objectEnumValues.classes.DbNull,
  JsonNull: objectEnumValues.classes.JsonNull,
  AnyNull: objectEnumValues.classes.AnyNull
}





/**
 * Enums
 */
exports.Prisma.TransactionIsolationLevel = makeStrictEnum({
  ReadUncommitted: 'ReadUncommitted',
  ReadCommitted: 'ReadCommitted',
  RepeatableRead: 'RepeatableRead',
  Serializable: 'Serializable'
});

exports.Prisma.LLMModelScalarFieldEnum = {
  id: 'id',
  name: 'name',
  rpm: 'rpm',
  rpd: 'rpd',
  tpm: 'tpm',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.SamplingProfileScalarFieldEnum = {
  id: 'id',
  profile_name: 'profile_name',
  temperature: 'temperature',
  top_k: 'top_k',
  top_p: 'top_p',
  presence_penalty: 'presence_penalty',
  frequency_penalty: 'frequency_penalty',
  max_tokens: 'max_tokens',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.PromptScalarFieldEnum = {
  id: 'id',
  prompt: 'prompt',
  tokens: 'tokens',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.ModelToPromptScalarFieldEnum = {
  model_id: 'model_id',
  prompt_id: 'prompt_id',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.ProfileToPromptScalarFieldEnum = {
  profile_id: 'profile_id',
  prompt_id: 'prompt_id',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.PromptResponseScalarFieldEnum = {
  id: 'id',
  prompt_id: 'prompt_id',
  model_id: 'model_id',
  profile_id: 'profile_id',
  response: 'response',
  createdAt: 'createdAt',
  updatedAt: 'updatedAt'
};

exports.Prisma.SortOrder = {
  asc: 'asc',
  desc: 'desc'
};

exports.Prisma.QueryMode = {
  default: 'default',
  insensitive: 'insensitive'
};

exports.Prisma.NullsOrder = {
  first: 'first',
  last: 'last'
};


exports.Prisma.ModelName = {
  LLMModel: 'LLMModel',
  SamplingProfile: 'SamplingProfile',
  Prompt: 'Prompt',
  ModelToPrompt: 'ModelToPrompt',
  ProfileToPrompt: 'ProfileToPrompt',
  PromptResponse: 'PromptResponse'
};
/**
 * Create the Client
 */
const config = {
  "generator": {
    "name": "client",
    "provider": {
      "fromEnvVar": null,
      "value": "prisma-client-js"
    },
    "output": {
      "value": "/Users/syedfaizan/Desktop/assignments/gen-ai-labs/apps/api/generated",
      "fromEnvVar": null
    },
    "config": {
      "engineType": "library"
    },
    "binaryTargets": [
      {
        "fromEnvVar": null,
        "value": "darwin-arm64",
        "native": true
      }
    ],
    "previewFeatures": [],
    "sourceFilePath": "/Users/syedfaizan/Desktop/assignments/gen-ai-labs/apps/api/prisma/schema.prisma",
    "isCustomOutput": true
  },
  "relativeEnvPaths": {
    "rootEnvPath": null
  },
  "relativePath": "../prisma",
  "clientVersion": "6.17.1",
  "engineVersion": "272a37d34178c2894197e17273bf937f25acdeac",
  "datasourceNames": [
    "db"
  ],
  "activeProvider": "postgresql",
  "inlineDatasources": {
    "db": {
      "url": {
        "fromEnvVar": "DATABASE_URL",
        "value": null
      }
    }
  },
  "inlineSchema": "// This is your Prisma schema file,\n// learn more about it in the docs: https://pris.ly/d/prisma-schema\n\n// Looking for ways to speed up your queries, or scale easily with your serverless or edge functions?\n// Try Prisma Accelerate: https://pris.ly/cli/accelerate-init\n\ngenerator client {\n  provider = \"prisma-client-js\"\n  output   = \"../generated\"\n}\n\ndatasource db {\n  provider = \"postgresql\"\n  url      = env(\"DATABASE_URL\")\n}\n\nmodel LLMModel {\n  id        String           @id @default(uuid()) @db.Uuid\n  name      String           @unique\n  rpm       Int\n  rpd       Int\n  tpm       Int\n  createdAt DateTime         @default(now())\n  updatedAt DateTime         @updatedAt\n  prompts   ModelToPrompt[]\n  responses PromptResponse[]\n\n  @@map(\"llm_model\")\n}\n\nmodel SamplingProfile {\n  id                String            @id @default(uuid()) @db.Uuid\n  profile_name      String            @db.VarChar(255)\n  temperature       Float             @default(0.0)\n  top_k             Float             @default(0.0)\n  top_p             Float             @default(0.0)\n  presence_penalty  Float?\n  frequency_penalty Float?\n  max_tokens        Int?              @default(512)\n  createdAt         DateTime          @default(now())\n  updatedAt         DateTime          @updatedAt\n  prompts           ProfileToPrompt[]\n  responses         PromptResponse[]\n\n  @@map(\"sampling_profile\")\n}\n\nmodel Prompt {\n  id        String            @id @default(uuid()) @db.Uuid\n  prompt    String            @db.VarChar(255)\n  tokens    Int               @default(0)\n  createdAt DateTime          @default(now())\n  updatedAt DateTime          @updatedAt\n  profiles  ProfileToPrompt[]\n  models    ModelToPrompt[]\n  responses PromptResponse[]\n\n  @@map(\"prompt\")\n}\n\nmodel ModelToPrompt {\n  model_id  String   @db.Uuid\n  model     LLMModel @relation(fields: [model_id], references: [id])\n  prompt_id String   @db.Uuid\n  prompt    Prompt   @relation(fields: [prompt_id], references: [id])\n  createdAt DateTime @default(now())\n  updatedAt DateTime @updatedAt\n\n  @@id([model_id, prompt_id])\n  @@index([model_id])\n  @@index([prompt_id])\n  @@map(\"model_to_prompt\")\n}\n\nmodel ProfileToPrompt {\n  profile_id String          @db.Uuid\n  profile    SamplingProfile @relation(fields: [profile_id], references: [id])\n  prompt_id  String          @db.Uuid\n  prompt     Prompt          @relation(fields: [prompt_id], references: [id])\n  createdAt  DateTime        @default(now())\n  updatedAt  DateTime        @updatedAt\n\n  @@id([profile_id, prompt_id])\n  @@index([profile_id])\n  @@index([prompt_id])\n  @@map(\"profile_to_prompt\")\n}\n\nmodel PromptResponse {\n  id         String          @id @default(uuid()) @db.Uuid\n  prompt_id  String          @db.Uuid\n  prompt     Prompt          @relation(fields: [prompt_id], references: [id])\n  model_id   String          @db.Uuid\n  model      LLMModel        @relation(fields: [model_id], references: [id])\n  profile_id String          @db.Uuid\n  profile    SamplingProfile @relation(fields: [profile_id], references: [id])\n  response   String?         @db.VarChar(255)\n  createdAt  DateTime        @default(now())\n  updatedAt  DateTime        @updatedAt\n\n  @@index([prompt_id])\n  @@index([model_id])\n  @@index([profile_id])\n  @@map(\"prompt_response\")\n}\n",
  "inlineSchemaHash": "d182f9f43c1ec5054850c63c77fc495aa5bbe51871a41da55b30d1fc7373dc93",
  "copyEngine": true
}
config.dirname = '/'

config.runtimeDataModel = JSON.parse("{\"models\":{\"LLMModel\":{\"fields\":[{\"name\":\"id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"name\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"rpm\",\"kind\":\"scalar\",\"type\":\"Int\"},{\"name\":\"rpd\",\"kind\":\"scalar\",\"type\":\"Int\"},{\"name\":\"tpm\",\"kind\":\"scalar\",\"type\":\"Int\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"prompts\",\"kind\":\"object\",\"type\":\"ModelToPrompt\",\"relationName\":\"LLMModelToModelToPrompt\"},{\"name\":\"responses\",\"kind\":\"object\",\"type\":\"PromptResponse\",\"relationName\":\"LLMModelToPromptResponse\"}],\"dbName\":\"llm_model\"},\"SamplingProfile\":{\"fields\":[{\"name\":\"id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"profile_name\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"temperature\",\"kind\":\"scalar\",\"type\":\"Float\"},{\"name\":\"top_k\",\"kind\":\"scalar\",\"type\":\"Float\"},{\"name\":\"top_p\",\"kind\":\"scalar\",\"type\":\"Float\"},{\"name\":\"presence_penalty\",\"kind\":\"scalar\",\"type\":\"Float\"},{\"name\":\"frequency_penalty\",\"kind\":\"scalar\",\"type\":\"Float\"},{\"name\":\"max_tokens\",\"kind\":\"scalar\",\"type\":\"Int\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"prompts\",\"kind\":\"object\",\"type\":\"ProfileToPrompt\",\"relationName\":\"ProfileToPromptToSamplingProfile\"},{\"name\":\"responses\",\"kind\":\"object\",\"type\":\"PromptResponse\",\"relationName\":\"PromptResponseToSamplingProfile\"}],\"dbName\":\"sampling_profile\"},\"Prompt\":{\"fields\":[{\"name\":\"id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"prompt\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"tokens\",\"kind\":\"scalar\",\"type\":\"Int\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"profiles\",\"kind\":\"object\",\"type\":\"ProfileToPrompt\",\"relationName\":\"ProfileToPromptToPrompt\"},{\"name\":\"models\",\"kind\":\"object\",\"type\":\"ModelToPrompt\",\"relationName\":\"ModelToPromptToPrompt\"},{\"name\":\"responses\",\"kind\":\"object\",\"type\":\"PromptResponse\",\"relationName\":\"PromptToPromptResponse\"}],\"dbName\":\"prompt\"},\"ModelToPrompt\":{\"fields\":[{\"name\":\"model_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"model\",\"kind\":\"object\",\"type\":\"LLMModel\",\"relationName\":\"LLMModelToModelToPrompt\"},{\"name\":\"prompt_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"prompt\",\"kind\":\"object\",\"type\":\"Prompt\",\"relationName\":\"ModelToPromptToPrompt\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"}],\"dbName\":\"model_to_prompt\"},\"ProfileToPrompt\":{\"fields\":[{\"name\":\"profile_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"profile\",\"kind\":\"object\",\"type\":\"SamplingProfile\",\"relationName\":\"ProfileToPromptToSamplingProfile\"},{\"name\":\"prompt_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"prompt\",\"kind\":\"object\",\"type\":\"Prompt\",\"relationName\":\"ProfileToPromptToPrompt\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"}],\"dbName\":\"profile_to_prompt\"},\"PromptResponse\":{\"fields\":[{\"name\":\"id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"prompt_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"prompt\",\"kind\":\"object\",\"type\":\"Prompt\",\"relationName\":\"PromptToPromptResponse\"},{\"name\":\"model_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"model\",\"kind\":\"object\",\"type\":\"LLMModel\",\"relationName\":\"LLMModelToPromptResponse\"},{\"name\":\"profile_id\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"profile\",\"kind\":\"object\",\"type\":\"SamplingProfile\",\"relationName\":\"PromptResponseToSamplingProfile\"},{\"name\":\"response\",\"kind\":\"scalar\",\"type\":\"String\"},{\"name\":\"createdAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"},{\"name\":\"updatedAt\",\"kind\":\"scalar\",\"type\":\"DateTime\"}],\"dbName\":\"prompt_response\"}},\"enums\":{},\"types\":{}}")
defineDmmfProperty(exports.Prisma, config.runtimeDataModel)
config.engineWasm = {
  getRuntime: async () => require('./query_engine_bg.js'),
  getQueryEngineWasmModule: async () => {
    const loader = (await import('#wasm-engine-loader')).default
    const engine = (await loader).default
    return engine
  }
}
config.compilerWasm = undefined

config.injectableEdgeEnv = () => ({
  parsed: {
    DATABASE_URL: typeof globalThis !== 'undefined' && globalThis['DATABASE_URL'] || typeof process !== 'undefined' && process.env && process.env.DATABASE_URL || undefined
  }
})

if (typeof globalThis !== 'undefined' && globalThis['DEBUG'] || typeof process !== 'undefined' && process.env && process.env.DEBUG || undefined) {
  Debug.enable(typeof globalThis !== 'undefined' && globalThis['DEBUG'] || typeof process !== 'undefined' && process.env && process.env.DEBUG || undefined)
}

const PrismaClient = getPrismaClient(config)
exports.PrismaClient = PrismaClient
Object.assign(exports, Prisma)

